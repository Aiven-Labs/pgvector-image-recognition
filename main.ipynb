{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image recognition with Python, OpenCV, OpenAI CLIP model and PostgreSQL `pgvector` \n",
    "\n",
    "This repository contains the working code for the example in the [blog post](https://aiven.io/developer/find-faces-with-pgvector)\n",
    "\n",
    "The below is the overall flow:\n",
    "\n",
    "![Overall flow](entire_flow.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Face recognition\n",
    "\n",
    "Detect the faces from the [test-image](test-image.png) picture and store them under the `stored-faces` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the cv2 library\n",
    "import cv2\n",
    "\n",
    "# loading the haar case algorithm file into alg variable\n",
    "alg = \"haarcascade_frontalface_default.xml\"\n",
    "# passing the algorithm to OpenCV\n",
    "haar_cascade = cv2.CascadeClassifier(alg)\n",
    "# loading the image path into file_name variable - replace <INSERT YOUR IMAGE NAME HERE> with the path to your image\n",
    "file_name = \"test-image.png\"\n",
    "# reading the image\n",
    "img = cv2.imread(file_name, 0)\n",
    "# creating a black and white version of the image\n",
    "gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "# detecting the faces\n",
    "faces = haar_cascade.detectMultiScale(\n",
    "    gray_img, scaleFactor=1.05, minNeighbors=2, minSize=(100, 100)\n",
    ")\n",
    "\n",
    "i = 0\n",
    "# for each face detected\n",
    "for x, y, w, h in faces:\n",
    "    # crop the image to select only the face\n",
    "    cropped_image = img[y : y + h, x : x + w]\n",
    "    # loading the target image path into target_file_name variable  - replace <INSERT YOUR TARGET IMAGE NAME HERE> with the path to your target image\n",
    "    target_file_name = 'stored-faces/' + str(i) + '.jpg'\n",
    "    cv2.imwrite(\n",
    "        target_file_name,\n",
    "        cropped_image,\n",
    "    )\n",
    "    i = i + 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Embeddings Calculation\n",
    "\n",
    "Calculate embeddings from the faces and pushing to PostgreSQL, you'll need to change the `<SERVICE_URI>` parameter with the PostgreSQL Service URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "import numpy as np\n",
    "from imgbeddings import imgbeddings\n",
    "from PIL import Image\n",
    "import psycopg2\n",
    "import os\n",
    "\n",
    "# connecting to the database - replace the SERVICE URI with the service URI\n",
    "conn = psycopg2.connect(\"<SERVICE_URI>\")\n",
    "\n",
    "for filename in os.listdir(\"stored-faces\"):\n",
    "    # opening the image\n",
    "    img = Image.open(\"stored-faces/\" + filename)\n",
    "    # loading the `imgbeddings`\n",
    "    ibed = imgbeddings()\n",
    "    # calculating the embeddings\n",
    "    embedding = ibed.to_embeddings(img)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"INSERT INTO pictures values (%s,%s)\", (filename, embedding[0].tolist()))\n",
    "    print(filename)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Calculate embeddings on a new picture\n",
    "\n",
    "Find the face and calculate the embeddings on the picture `solo-image.png` used for research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the face image path into file_name variable\n",
    "file_name = \"solo-image.png\"  # replace <INSERT YOUR FACE FILE NAME> with the path to your image\n",
    "# opening the image\n",
    "img = Image.open(file_name)\n",
    "# loading the `imgbeddings`\n",
    "ibed = imgbeddings()\n",
    "# calculating the embeddings\n",
    "embedding = ibed.to_embeddings(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Find similar images by querying the Postgresql database using pgvector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "cur = conn.cursor()\n",
    "string_representation = \"[\"+ \",\".join(str(x) for x in embedding[0].tolist()) +\"]\"\n",
    "cur.execute(\"SELECT * FROM pictures ORDER BY embedding <-> %s LIMIT 1;\", (string_representation,))\n",
    "rows = cur.fetchall()\n",
    "for row in rows:\n",
    "    display(Image(filename=\"stored-faces/\"+row[0]))\n",
    "cur.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
